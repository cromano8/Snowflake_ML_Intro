{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "from snowflake.ml.modeling.impute import SimpleImputer\n",
    "from snowflake.ml.modeling.metrics import accuracy_score\n",
    "from snowflake.ml.modeling.model_selection import GridSearchCV\n",
    "from snowflake.ml.modeling.preprocessing import OneHotEncoder\n",
    "from snowflake.ml.modeling.xgboost import XGBClassifier\n",
    "from snowflake.ml.registry import Registry\n",
    "from snowflake.ml.utils.connection_params import SnowflakeLoginOptions\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark import types as T\n",
    "from snowflake.snowpark.functions import col\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SnowflakeLoginOptions() is in private preview since 0.2.0. Do not use it in production. \n"
     ]
    }
   ],
   "source": [
    "session = Session.builder.configs(SnowflakeLoginOptions()).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = session.table(\"titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"SURVIVED\"  |\"PCLASS\"  |\"AGE\"  |\"SIBSP\"  |\"PARCH\"  |\"FARE\"   |\"ADULT_MALE\"  |\"DECK\"  |\"ALIVE\"  |\"ALONE\"  |\"SEX\"   |\"EMBARKED\"  |\"CLASS\"  |\"WHO\"  |\"EMBARK_TOWN\"  |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|0           |3         |22.00  |1        |0        |7.2500   |True          |NULL    |False    |False    |MALE    |S           |THIRD    |MAN    |SOUTHAMPTON    |\n",
      "|1           |1         |38.00  |1        |0        |71.2833  |False         |C       |True     |False    |FEMALE  |C           |FIRST    |WOMAN  |CHERBOURG      |\n",
      "|1           |3         |26.00  |0        |0        |7.9250   |False         |NULL    |True     |True     |FEMALE  |S           |THIRD    |WOMAN  |SOUTHAMPTON    |\n",
      "|1           |1         |35.00  |1        |0        |53.1000  |False         |C       |True     |False    |FEMALE  |S           |FIRST    |WOMAN  |SOUTHAMPTON    |\n",
      "|0           |3         |35.00  |0        |0        |8.0500   |True          |NULL    |False    |True     |MALE    |S           |THIRD    |MAN    |SOUTHAMPTON    |\n",
      "|0           |3         |NULL   |0        |0        |8.4583   |True          |NULL    |False    |True     |MALE    |Q           |THIRD    |MAN    |QUEENSTOWN     |\n",
      "|0           |1         |54.00  |0        |0        |51.8625  |True          |E       |False    |True     |MALE    |S           |FIRST    |MAN    |SOUTHAMPTON    |\n",
      "|0           |3         |2.00   |3        |1        |21.0750  |False         |NULL    |False    |False    |MALE    |S           |THIRD    |CHILD  |SOUTHAMPTON    |\n",
      "|1           |3         |27.00  |0        |2        |11.1333  |False         |NULL    |True     |False    |FEMALE  |S           |THIRD    |WOMAN  |SOUTHAMPTON    |\n",
      "|1           |2         |14.00  |1        |0        |30.0708  |False         |NULL    |True     |False    |FEMALE  |C           |SECOND   |CHILD  |CHERBOURG      |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AGE': 177, 'DECK': 688, 'EMBARKED': 2, 'EMBARK_TOWN': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns with null values and their respective counts\n",
    "{\n",
    "    k: v\n",
    "    for k, v in {\n",
    "        col_name: titanic_df.where(col(col_name).is_null()).count()\n",
    "        for col_name in titanic_df.columns\n",
    "    }.items()\n",
    "    if v > 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.drop(\n",
    "    [\"AGE\", \"DECK\", \"ALIVE\", \"ADULT_MALE\", \"EMBARKED\", \"SEX\", \"PCLASS\", \"ALONE\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------\n",
      "|\"SURVIVED\"  |\"SIBSP\"  |\"PARCH\"  |\"CLASS\"  |\"WHO\"  |\"EMBARK_TOWN\"  |\"FARE\"   |\n",
      "------------------------------------------------------------------------------\n",
      "|0           |1        |0        |THIRD    |MAN    |SOUTHAMPTON    |7.25     |\n",
      "|1           |1        |0        |FIRST    |WOMAN  |CHERBOURG      |71.2833  |\n",
      "|1           |0        |0        |THIRD    |WOMAN  |SOUTHAMPTON    |7.925    |\n",
      "|1           |1        |0        |FIRST    |WOMAN  |SOUTHAMPTON    |53.1     |\n",
      "|0           |0        |0        |THIRD    |MAN    |SOUTHAMPTON    |8.05     |\n",
      "|0           |0        |0        |THIRD    |MAN    |QUEENSTOWN     |8.4583   |\n",
      "|0           |0        |0        |FIRST    |MAN    |SOUTHAMPTON    |51.8625  |\n",
      "|0           |3        |1        |THIRD    |CHILD  |SOUTHAMPTON    |21.075   |\n",
      "|1           |0        |2        |THIRD    |WOMAN  |SOUTHAMPTON    |11.1333  |\n",
      "|1           |1        |0        |SECOND   |CHILD  |CHERBOURG      |30.0708  |\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df = titanic_df.withColumn(\"FARE\", titanic_df[\"FARE\"].astype(T.FloatType()))\n",
    "\n",
    "titanic_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\"CLASS\", \"WHO\", \"EMBARK_TOWN\"]\n",
    "num_cols = [\"SIBSP\", \"PARCH\", \"FARE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------\n",
      "|\"CLASS\"  |\"WHO\"  |\"EMBARK_TOWN\"  |\"SURVIVED\"  |\"SIBSP\"  |\"PARCH\"  |\"FARE\"   |\n",
      "------------------------------------------------------------------------------\n",
      "|THIRD    |MAN    |SOUTHAMPTON    |0           |1        |0        |7.25     |\n",
      "|FIRST    |WOMAN  |CHERBOURG      |1           |1        |0        |71.2833  |\n",
      "|THIRD    |WOMAN  |SOUTHAMPTON    |1           |0        |0        |7.925    |\n",
      "|FIRST    |WOMAN  |SOUTHAMPTON    |1           |1        |0        |53.1     |\n",
      "|THIRD    |MAN    |SOUTHAMPTON    |0           |0        |0        |8.05     |\n",
      "|THIRD    |MAN    |QUEENSTOWN     |0           |0        |0        |8.4583   |\n",
      "|FIRST    |MAN    |SOUTHAMPTON    |0           |0        |0        |51.8625  |\n",
      "|THIRD    |CHILD  |SOUTHAMPTON    |0           |3        |1        |21.075   |\n",
      "|THIRD    |WOMAN  |SOUTHAMPTON    |1           |0        |2        |11.1333  |\n",
      "|SECOND   |CHILD  |CHERBOURG      |1           |1        |0        |30.0708  |\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "impute_cat = SimpleImputer(\n",
    "    input_cols=cat_cols,\n",
    "    output_cols=cat_cols,\n",
    "    strategy=\"most_frequent\",\n",
    "    drop_input_cols=True,\n",
    ")\n",
    "\n",
    "titanic_df = impute_cat.fit(titanic_df).transform(titanic_df)\n",
    "titanic_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"CLASS_SECOND\"  |\"CLASS_THIRD\"  |\"WHO_MAN\"  |\"WHO_WOMAN\"  |\"EMBARK_TOWN_QUEENSTOWN\"  |\"EMBARK_TOWN_SOUTHAMPTON\"  |\"SURVIVED\"  |\"SIBSP\"  |\"PARCH\"  |\"FARE\"   |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|0.0             |1.0            |1.0        |0.0          |0.0                       |1.0                        |0           |1        |0        |7.25     |\n",
      "|0.0             |0.0            |0.0        |1.0          |0.0                       |0.0                        |1           |1        |0        |71.2833  |\n",
      "|0.0             |1.0            |0.0        |1.0          |0.0                       |1.0                        |1           |0        |0        |7.925    |\n",
      "|0.0             |0.0            |0.0        |1.0          |0.0                       |1.0                        |1           |1        |0        |53.1     |\n",
      "|0.0             |1.0            |1.0        |0.0          |0.0                       |1.0                        |0           |0        |0        |8.05     |\n",
      "|0.0             |1.0            |1.0        |0.0          |1.0                       |0.0                        |0           |0        |0        |8.4583   |\n",
      "|0.0             |0.0            |1.0        |0.0          |0.0                       |1.0                        |0           |0        |0        |51.8625  |\n",
      "|0.0             |1.0            |0.0        |0.0          |0.0                       |1.0                        |0           |3        |1        |21.075   |\n",
      "|0.0             |1.0            |0.0        |1.0          |0.0                       |1.0                        |1           |0        |2        |11.1333  |\n",
      "|1.0             |0.0            |0.0        |0.0          |0.0                       |0.0                        |1           |1        |0        |30.0708  |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "OHE = OneHotEncoder(\n",
    "    input_cols=cat_cols,\n",
    "    output_cols=cat_cols,\n",
    "    drop_input_cols=True,\n",
    "    drop=\"first\",\n",
    "    handle_unknown=\"ignore\",\n",
    ")\n",
    "\n",
    "titanic_df = OHE.fit(titanic_df).transform(titanic_df)\n",
    "titanic_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = titanic_df.random_split(weights=[0.8, 0.2], seed=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"n_estimators\": [100, 200, 300, 400, 500],\n",
    "    \"learning_rate\": [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    \"max_depth\": list(range(3, 6, 1)),\n",
    "    \"min_child_weight\": list(range(1, 6, 1)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [100, 200, 300, 400, 500],\n",
       " 'learning_rate': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
       " 'max_depth': [3, 4, 5],\n",
       " 'min_child_weight': [1, 2, 3, 4, 5]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Statement executed successfully.')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql(\n",
    "    f\"ALTER WAREHOUSE {session.get_current_warehouse()[1:-1]} SET WAREHOUSE_SIZE=LARGE;\"\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data scientists may not have the ability to change the warehouse size.  They will usually have access to a larger warehouse and can easily switch as well using session.use_warehouse('bigger_warehouse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Package 'fastparquet' is not installed in the local environment. Your UDF might not work when the package is installed on the server but not on your local environment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<snowflake.ml.modeling.model_selection.grid_search_cv.GridSearchCV at 0x7fcad8f85a20>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator=XGBClassifier(),\n",
    "    param_grid=parameters,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"accuracy\",\n",
    "    input_cols=train_df.drop(\"SURVIVED\").columns,\n",
    "    label_cols=\"SURVIVED\",\n",
    "    output_cols=\"PRED_SURVIVED\",\n",
    ")\n",
    "\n",
    "# Train\n",
    "grid_search.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Statement executed successfully.')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql(\n",
    "    f\"ALTER WAREHOUSE {session.get_current_warehouse()[1:-1]} SET WAREHOUSE_SIZE=XSMALL;\"\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = grid_search.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.819149\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(\n",
    "    df=result, y_true_col_names=\"SURVIVED\", y_pred_col_names=\"PRED_SURVIVED\"\n",
    ")\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.822148</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>0.820760</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0.820760</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.820750</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.820740</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy  learning_rate  max_depth  min_child_weight  n_estimators\n",
       "94   0.822148            0.2          3                 4           500\n",
       "311  0.820760            0.5          3                 3           200\n",
       "216  0.820760            0.3          5                 4           200\n",
       "114  0.820750            0.2          4                 3           500\n",
       "299  0.820740            0.4          5                 5           500"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print each combination of hyperparameters with their accuracy\n",
    "results = grid_search.to_sklearn().cv_results_\n",
    "data = {\"accuracy\": results[\"mean_test_score\"]}\n",
    "for i, param in enumerate(results[\"params\"]):\n",
    "    for key, value in param.items():\n",
    "        if key not in data:\n",
    "            data[key] = [None] * len(results[\"params\"])\n",
    "        data[key][i] = value\n",
    "\n",
    "# Create DataFrame\n",
    "hp_df = pd.DataFrame(data).sort_values(by=\"accuracy\", ascending=False)\n",
    "hp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Registry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_model = grid_search.to_sklearn().best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to add one to our model versions if it already exists\n",
    "\n",
    "\n",
    "def check_and_update(df, model_name):\n",
    "    if df.empty:\n",
    "        return \"V_1\"\n",
    "    elif df[df[\"name\"] == model_name].empty:\n",
    "        return \"V_1\"\n",
    "    else:\n",
    "        # Increment model_version if df is not a pandas Series\n",
    "        lst = sorted(ast.literal_eval(df[\"versions\"][0]))\n",
    "        last_value = lst[-1]\n",
    "        prefix, num = last_value.rsplit(\"_\", 1)\n",
    "        new_last_value = f\"{prefix}_{int(num)+1}\"\n",
    "        lst[-1] = new_last_value\n",
    "        return new_last_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:snowflake.connector.vendored.urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /?accelerate\n"
     ]
    }
   ],
   "source": [
    "# Get sample input data to pass into the registry logging function\n",
    "X = train_df.drop(\"SURVIVED\").limit(100)\n",
    "\n",
    "# Create a registry and log the model\n",
    "# You can specify a different DB and Schema if you'd like\n",
    "# otherwise it uses the session context\n",
    "reg = Registry(session=session)\n",
    "\n",
    "reg_df = reg.show_models()\n",
    "\n",
    "# Define model name and version (use uppercase for name)\n",
    "model_name = \"TITANIC\"\n",
    "\n",
    "model_version = check_and_update(reg_df, model_name)\n",
    "\n",
    "titanic_model = reg.log_model(\n",
    "    model_name=model_name,\n",
    "    version_name=model_version,\n",
    "    model=optimal_model,\n",
    "    sample_input_data=X,\n",
    ")\n",
    "\n",
    "# Add evaluation metric\n",
    "titanic_model.set_metric(\n",
    "    metric_name=\"accuracy\",\n",
    "    value=hp_df[\"accuracy\"][0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_on</th>\n",
       "      <th>name</th>\n",
       "      <th>database_name</th>\n",
       "      <th>schema_name</th>\n",
       "      <th>comment</th>\n",
       "      <th>owner</th>\n",
       "      <th>default_version_name</th>\n",
       "      <th>versions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-14 08:33:34.069000-07:00</td>\n",
       "      <td>TITANIC</td>\n",
       "      <td>SNOWPARK</td>\n",
       "      <td>TITANIC</td>\n",
       "      <td>None</td>\n",
       "      <td>SYSADMIN</td>\n",
       "      <td>V_1</td>\n",
       "      <td>[\"V_1\",\"V_2\",\"V_3\"]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        created_on     name database_name schema_name comment  \\\n",
       "0 2024-03-14 08:33:34.069000-07:00  TITANIC      SNOWPARK     TITANIC    None   \n",
       "\n",
       "      owner default_version_name             versions  \n",
       "0  SYSADMIN                  V_1  [\"V_1\",\"V_2\",\"V_3\"]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.show_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    k: v for k, v in optimal_model.get_params().items() if v and k != \"missing\"\n",
    "}\n",
    "titanic_model.set_metric(metric_name=\"hyperparameters\", value=hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_on</th>\n",
       "      <th>name</th>\n",
       "      <th>comment</th>\n",
       "      <th>database_name</th>\n",
       "      <th>schema_name</th>\n",
       "      <th>module_name</th>\n",
       "      <th>is_default_version</th>\n",
       "      <th>functions</th>\n",
       "      <th>metadata</th>\n",
       "      <th>user_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-14 08:33:34.121000-07:00</td>\n",
       "      <td>V_1</td>\n",
       "      <td>None</td>\n",
       "      <td>SNOWPARK</td>\n",
       "      <td>TITANIC</td>\n",
       "      <td>TITANIC</td>\n",
       "      <td>true</td>\n",
       "      <td>[\"PREDICT_PROBA\",\"PREDICT\",\"APPLY\"]</td>\n",
       "      <td>{\"metrics\": {\"accuracy\": 0.8093617021276595, \"hyperparameters\": {\"objective\": \"binary:logistic\", \"learning_rate\": 0.2, \"max_depth\": 3, \"min_child_weight\": 4, \"n_estimators\": 500, \"n_jobs\": 3}}, \"snowpark_ml_schema_version\": \"2024-01-01\"}</td>\n",
       "      <td>{\"snowpark_ml_data\":{\"functions\":[{\"name\":\"APPLY\",\"signature\":{\"inputs\":[{\"name\":\"CLASS_SECOND\",\"type\":\"DOUBLE\"},{\"name\":\"CLASS_THIRD\",\"type\":\"DOUBLE\"},{\"name\":\"WHO_MAN\",\"type\":\"DOUBLE\"},{\"name\":\"WHO_WOMAN\",\"type\":\"DOUBLE\"},{\"name\":\"EMBARK_TOWN_QUEENSTOWN\",\"type\":\"DOUBLE\"},{\"name\":\"EMBARK_TOWN_SOUTHAMPTON\",\"type\":\"DOUBLE\"},{\"name\":\"SIBSP\",\"type\":\"INT8\"},{\"name\":\"PARCH\",\"type\":\"INT8\"},{\"name\":\"FARE\",\"type\":\"DOUBLE\"}],\"outputs\":[{\"name\":\"output_feature_0\",\"type\":\"FLOAT\"},{\"name\":\"output_featur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03-15 10:35:26.454000-07:00</td>\n",
       "      <td>V_2</td>\n",
       "      <td>None</td>\n",
       "      <td>SNOWPARK</td>\n",
       "      <td>TITANIC</td>\n",
       "      <td>TITANIC</td>\n",
       "      <td>false</td>\n",
       "      <td>[\"PREDICT_PROBA\",\"PREDICT\",\"APPLY\"]</td>\n",
       "      <td>{\"metrics\": {\"accuracy\": 0.8093617021276595, \"hyperparameters\": {\"objective\": \"binary:logistic\", \"learning_rate\": 0.2, \"max_depth\": 3, \"min_child_weight\": 4, \"n_estimators\": 500, \"n_jobs\": 3}}, \"snowpark_ml_schema_version\": \"2024-01-01\"}</td>\n",
       "      <td>{\"snowpark_ml_data\":{\"functions\":[{\"name\":\"APPLY\",\"signature\":{\"inputs\":[{\"name\":\"CLASS_SECOND\",\"type\":\"DOUBLE\"},{\"name\":\"CLASS_THIRD\",\"type\":\"DOUBLE\"},{\"name\":\"WHO_MAN\",\"type\":\"DOUBLE\"},{\"name\":\"WHO_WOMAN\",\"type\":\"DOUBLE\"},{\"name\":\"EMBARK_TOWN_QUEENSTOWN\",\"type\":\"DOUBLE\"},{\"name\":\"EMBARK_TOWN_SOUTHAMPTON\",\"type\":\"DOUBLE\"},{\"name\":\"SIBSP\",\"type\":\"INT8\"},{\"name\":\"PARCH\",\"type\":\"INT8\"},{\"name\":\"FARE\",\"type\":\"DOUBLE\"}],\"outputs\":[{\"name\":\"output_feature_0\",\"type\":\"FLOAT\"},{\"name\":\"output_featur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-04-29 12:49:51.260000-07:00</td>\n",
       "      <td>V_3</td>\n",
       "      <td>None</td>\n",
       "      <td>SNOWPARK</td>\n",
       "      <td>TITANIC</td>\n",
       "      <td>TITANIC</td>\n",
       "      <td>false</td>\n",
       "      <td>[\"PREDICT_PROBA\",\"PREDICT\",\"APPLY\"]</td>\n",
       "      <td>{\"metrics\": {\"accuracy\": 0.8093617021276595, \"hyperparameters\": {\"objective\": \"binary:logistic\", \"learning_rate\": 0.2, \"max_depth\": 3, \"min_child_weight\": 4, \"n_estimators\": 500, \"n_jobs\": 3}}, \"snowpark_ml_schema_version\": \"2024-01-01\"}</td>\n",
       "      <td>{\"snowpark_ml_data\":{\"functions\":[{\"name\":\"APPLY\",\"signature\":{\"inputs\":[{\"name\":\"CLASS_SECOND\",\"type\":\"DOUBLE\"},{\"name\":\"CLASS_THIRD\",\"type\":\"DOUBLE\"},{\"name\":\"WHO_MAN\",\"type\":\"DOUBLE\"},{\"name\":\"WHO_WOMAN\",\"type\":\"DOUBLE\"},{\"name\":\"EMBARK_TOWN_QUEENSTOWN\",\"type\":\"DOUBLE\"},{\"name\":\"EMBARK_TOWN_SOUTHAMPTON\",\"type\":\"DOUBLE\"},{\"name\":\"SIBSP\",\"type\":\"INT8\"},{\"name\":\"PARCH\",\"type\":\"INT8\"},{\"name\":\"FARE\",\"type\":\"DOUBLE\"}],\"outputs\":[{\"name\":\"output_feature_0\",\"type\":\"FLOAT\"},{\"name\":\"output_featur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        created_on name comment database_name schema_name  \\\n",
       "0 2024-03-14 08:33:34.121000-07:00  V_1    None      SNOWPARK     TITANIC   \n",
       "1 2024-03-15 10:35:26.454000-07:00  V_2    None      SNOWPARK     TITANIC   \n",
       "2 2024-04-29 12:49:51.260000-07:00  V_3    None      SNOWPARK     TITANIC   \n",
       "\n",
       "  module_name is_default_version                            functions  \\\n",
       "0     TITANIC               true  [\"PREDICT_PROBA\",\"PREDICT\",\"APPLY\"]   \n",
       "1     TITANIC              false  [\"PREDICT_PROBA\",\"PREDICT\",\"APPLY\"]   \n",
       "2     TITANIC              false  [\"PREDICT_PROBA\",\"PREDICT\",\"APPLY\"]   \n",
       "\n",
       "                                                                                                                                                                                                                                        metadata  \\\n",
       "0  {\"metrics\": {\"accuracy\": 0.8093617021276595, \"hyperparameters\": {\"objective\": \"binary:logistic\", \"learning_rate\": 0.2, \"max_depth\": 3, \"min_child_weight\": 4, \"n_estimators\": 500, \"n_jobs\": 3}}, \"snowpark_ml_schema_version\": \"2024-01-01\"}   \n",
       "1  {\"metrics\": {\"accuracy\": 0.8093617021276595, \"hyperparameters\": {\"objective\": \"binary:logistic\", \"learning_rate\": 0.2, \"max_depth\": 3, \"min_child_weight\": 4, \"n_estimators\": 500, \"n_jobs\": 3}}, \"snowpark_ml_schema_version\": \"2024-01-01\"}   \n",
       "2  {\"metrics\": {\"accuracy\": 0.8093617021276595, \"hyperparameters\": {\"objective\": \"binary:logistic\", \"learning_rate\": 0.2, \"max_depth\": 3, \"min_child_weight\": 4, \"n_estimators\": 500, \"n_jobs\": 3}}, \"snowpark_ml_schema_version\": \"2024-01-01\"}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             user_data  \n",
       "0  {\"snowpark_ml_data\":{\"functions\":[{\"name\":\"APPLY\",\"signature\":{\"inputs\":[{\"name\":\"CLASS_SECOND\",\"type\":\"DOUBLE\"},{\"name\":\"CLASS_THIRD\",\"type\":\"DOUBLE\"},{\"name\":\"WHO_MAN\",\"type\":\"DOUBLE\"},{\"name\":\"WHO_WOMAN\",\"type\":\"DOUBLE\"},{\"name\":\"EMBARK_TOWN_QUEENSTOWN\",\"type\":\"DOUBLE\"},{\"name\":\"EMBARK_TOWN_SOUTHAMPTON\",\"type\":\"DOUBLE\"},{\"name\":\"SIBSP\",\"type\":\"INT8\"},{\"name\":\"PARCH\",\"type\":\"INT8\"},{\"name\":\"FARE\",\"type\":\"DOUBLE\"}],\"outputs\":[{\"name\":\"output_feature_0\",\"type\":\"FLOAT\"},{\"name\":\"output_featur...  \n",
       "1  {\"snowpark_ml_data\":{\"functions\":[{\"name\":\"APPLY\",\"signature\":{\"inputs\":[{\"name\":\"CLASS_SECOND\",\"type\":\"DOUBLE\"},{\"name\":\"CLASS_THIRD\",\"type\":\"DOUBLE\"},{\"name\":\"WHO_MAN\",\"type\":\"DOUBLE\"},{\"name\":\"WHO_WOMAN\",\"type\":\"DOUBLE\"},{\"name\":\"EMBARK_TOWN_QUEENSTOWN\",\"type\":\"DOUBLE\"},{\"name\":\"EMBARK_TOWN_SOUTHAMPTON\",\"type\":\"DOUBLE\"},{\"name\":\"SIBSP\",\"type\":\"INT8\"},{\"name\":\"PARCH\",\"type\":\"INT8\"},{\"name\":\"FARE\",\"type\":\"DOUBLE\"}],\"outputs\":[{\"name\":\"output_feature_0\",\"type\":\"FLOAT\"},{\"name\":\"output_featur...  \n",
       "2  {\"snowpark_ml_data\":{\"functions\":[{\"name\":\"APPLY\",\"signature\":{\"inputs\":[{\"name\":\"CLASS_SECOND\",\"type\":\"DOUBLE\"},{\"name\":\"CLASS_THIRD\",\"type\":\"DOUBLE\"},{\"name\":\"WHO_MAN\",\"type\":\"DOUBLE\"},{\"name\":\"WHO_WOMAN\",\"type\":\"DOUBLE\"},{\"name\":\"EMBARK_TOWN_QUEENSTOWN\",\"type\":\"DOUBLE\"},{\"name\":\"EMBARK_TOWN_SOUTHAMPTON\",\"type\":\"DOUBLE\"},{\"name\":\"SIBSP\",\"type\":\"INT8\"},{\"name\":\"PARCH\",\"type\":\"INT8\"},{\"name\":\"FARE\",\"type\":\"DOUBLE\"}],\"outputs\":[{\"name\":\"output_feature_0\",\"type\":\"FLOAT\"},{\"name\":\"output_featur...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 500\n",
    "reg.get_model(model_name).show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have multiple versions of the model, we want the UDF to be deployed as the version with the highest accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df = reg.get_model(model_name).show_versions()\n",
    "reg_df[\"accuracy\"] = reg_df[\"metadata\"].apply(\n",
    "    lambda x: json.loads(x)[\"metrics\"][\"accuracy\"]\n",
    ")\n",
    "best_model = reg_df.sort_values(by=\"accuracy\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'V_1'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployed_version = best_model[\"name\"].iloc[0]\n",
    "deployed_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the default version to the deployed version (best model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'V_1'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = reg.get_model(model_name)\n",
    "m.default = deployed_version\n",
    "mv = m.default\n",
    "mv.version_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"CLASS_SECOND\"  |\"CLASS_THIRD\"  |\"WHO_MAN\"  |\"WHO_WOMAN\"  |\"EMBARK_TOWN_QUEENSTOWN\"  |\"EMBARK_TOWN_SOUTHAMPTON\"  |\"SURVIVED\"  |\"SIBSP\"  |\"PARCH\"  |\"FARE\"    |\"output_feature_0\"     |\"output_feature_1\"    |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|0.0             |1.0            |1.0        |0.0          |1.0                       |0.0                        |0           |0        |0        |8.4583    |0.9589072465896606     |0.041092731058597565  |\n",
      "|0.0             |0.0            |1.0        |0.0          |0.0                       |1.0                        |0           |0        |0        |51.8625   |0.8610950708389282     |0.13890492916107178   |\n",
      "|0.0             |1.0            |0.0        |0.0          |0.0                       |1.0                        |0           |3        |1        |21.075    |0.8630478382110596     |0.13695217669010162   |\n",
      "|1.0             |0.0            |0.0        |0.0          |0.0                       |0.0                        |1           |1        |0        |30.0708   |0.005812287330627441   |0.9941877126693726    |\n",
      "|0.0             |1.0            |1.0        |0.0          |0.0                       |1.0                        |0           |1        |5        |31.275    |0.8883638978004456     |0.11163610219955444   |\n",
      "|1.0             |0.0            |0.0        |1.0          |0.0                       |1.0                        |1           |0        |0        |16.0      |0.029041707515716553   |0.9709582924842834    |\n",
      "|0.0             |1.0            |0.0        |0.0          |0.0                       |1.0                        |0           |3        |1        |21.075    |0.8630478382110596     |0.13695217669010162   |\n",
      "|0.0             |1.0            |1.0        |0.0          |0.0                       |1.0                        |0           |0        |0        |7.8958    |0.9779325723648072     |0.022067449986934665  |\n",
      "|0.0             |0.0            |0.0        |1.0          |0.0                       |0.0                        |1           |1        |0        |146.5208  |0.0013046860694885254  |0.9986953139305116    |\n",
      "|0.0             |0.0            |1.0        |0.0          |0.0                       |0.0                        |0           |1        |0        |82.1708   |0.3023839592933655     |0.6976160407066345    |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "remote_prediction = mv.run(test_df, function_name=\"predict_proba\")\n",
    "remote_prediction.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To test in SQL write test data back to a table\n",
    "\n",
    "test_df.write.mode(\"overwrite\").save_as_table(\"TEST_DATA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add images to stage for Streamlit App\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PutResult(source='floating.webp', target='floating.webp.gz', source_size=205540, target_size=0, source_compression='NONE', target_compression='GZIP', status='SKIPPED', message=''),\n",
       " PutResult(source='flying.webp', target='flying.webp.gz', source_size=77798, target_size=0, source_compression='NONE', target_compression='GZIP', status='SKIPPED', message=''),\n",
       " PutResult(source='sinking.webp', target='sinking.webp.gz', source_size=148802, target_size=0, source_compression='NONE', target_compression='GZIP', status='SKIPPED', message='')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.file.put(\"../streamlit_images/*\", \"@ML_DATA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling Model from SQL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"CLASS_SECOND\"  |\"CLASS_THIRD\"  |\"WHO_MAN\"  |\"WHO_WOMAN\"  |\"EMBARK_TOWN_QUEENSTOWN\"  |\"EMBARK_TOWN_SOUTHAMPTON\"  |\"SIBSP\"  |\"PARCH\"  |\"FARE\"    |\"SURV_PRED\"            |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|0.0             |1.0            |1.0        |0.0          |1.0                       |0.0                        |0        |0        |8.4583    |0.9589072465896606     |\n",
      "|0.0             |0.0            |1.0        |0.0          |0.0                       |1.0                        |0        |0        |51.8625   |0.8610950708389282     |\n",
      "|0.0             |1.0            |0.0        |0.0          |0.0                       |1.0                        |3        |1        |21.075    |0.8630478382110596     |\n",
      "|1.0             |0.0            |0.0        |0.0          |0.0                       |0.0                        |1        |0        |30.0708   |0.005812287330627441   |\n",
      "|0.0             |1.0            |1.0        |0.0          |0.0                       |1.0                        |1        |5        |31.275    |0.8883638978004456     |\n",
      "|1.0             |0.0            |0.0        |1.0          |0.0                       |1.0                        |0        |0        |16.0      |0.029041707515716553   |\n",
      "|0.0             |1.0            |0.0        |0.0          |0.0                       |1.0                        |3        |1        |21.075    |0.8630478382110596     |\n",
      "|0.0             |1.0            |1.0        |0.0          |0.0                       |1.0                        |0        |0        |7.8958    |0.9779325723648071     |\n",
      "|0.0             |0.0            |0.0        |1.0          |0.0                       |0.0                        |1        |0        |146.5208  |0.0013046860694885254  |\n",
      "|0.0             |0.0            |1.0        |0.0          |0.0                       |0.0                        |1        |0        |82.1708   |0.3023839592933655     |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Copy this code in a snowflake worksheet or run via session.sql\n",
    "inference_df = session.sql(\n",
    "    \"\"\"\n",
    "select *, TITANIC!predict_proba(*):output_feature_0\n",
    "as surv_pred\n",
    "from (\n",
    "select * exclude survived\n",
    "from test_data)\n",
    "            \"\"\"\n",
    ")\n",
    "inference_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling model from a new notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"CLASS_SECOND\"  |\"CLASS_THIRD\"  |\"WHO_MAN\"  |\"WHO_WOMAN\"  |\"EMBARK_TOWN_QUEENSTOWN\"  |\"EMBARK_TOWN_SOUTHAMPTON\"  |\"SURVIVED\"  |\"SIBSP\"  |\"PARCH\"  |\"FARE\"    |\"PRED_SURVIVED\"       |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|0.0             |1.0            |1.0        |0.0          |1.0                       |0.0                        |0           |0        |0        |8.4583    |0.041092731058597565  |\n",
      "|0.0             |0.0            |1.0        |0.0          |0.0                       |1.0                        |0           |0        |0        |51.8625   |0.13890492916107178   |\n",
      "|0.0             |1.0            |0.0        |0.0          |0.0                       |1.0                        |0           |3        |1        |21.075    |0.13695217669010162   |\n",
      "|1.0             |0.0            |0.0        |0.0          |0.0                       |0.0                        |1           |1        |0        |30.0708   |0.9941877126693726    |\n",
      "|0.0             |1.0            |1.0        |0.0          |0.0                       |1.0                        |0           |1        |5        |31.275    |0.11163610219955444   |\n",
      "|1.0             |0.0            |0.0        |1.0          |0.0                       |1.0                        |1           |0        |0        |16.0      |0.9709582924842834    |\n",
      "|0.0             |1.0            |0.0        |0.0          |0.0                       |1.0                        |0           |3        |1        |21.075    |0.13695217669010162   |\n",
      "|0.0             |1.0            |1.0        |0.0          |0.0                       |1.0                        |0           |0        |0        |7.8958    |0.022067449986934665  |\n",
      "|0.0             |0.0            |0.0        |1.0          |0.0                       |0.0                        |1           |1        |0        |146.5208  |0.9986953139305116    |\n",
      "|0.0             |0.0            |1.0        |0.0          |0.0                       |0.0                        |0           |1        |0        |82.1708   |0.6976160407066345    |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Point to the registry\n",
    "\n",
    "reg = Registry(session=session)\n",
    "\n",
    "# Get the default version of your model (Model with best accuracy in our case)\n",
    "\n",
    "mv = reg.get_model(\"titanic\").default\n",
    "\n",
    "remote_prediction = mv.run(test_df, function_name=\"predict_proba\")\n",
    "remote_prediction.drop('\"output_feature_0\"').with_column_renamed(\n",
    "    '\"output_feature_1\"', \"pred_survived\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To delete your model and all of it's versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg.delete_model(\"TITANIC\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Intro_SnowML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
